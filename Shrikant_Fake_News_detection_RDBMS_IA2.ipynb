{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "#import seaborn as sns\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the train and test datasets\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5) (5200, 4)\n"
     ]
    }
   ],
   "source": [
    "#print the shape i.e. total rows and columns\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data info: \n",
      "\n",
      "id           0\n",
      "title      558\n",
      "author    1957\n",
      "text        39\n",
      "label        0\n",
      "dtype: int64\n",
      "\n",
      "Test data info: \n",
      "\n",
      "id          0\n",
      "title     122\n",
      "author    503\n",
      "text        7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#find the total null values in each column\n",
    "\n",
    "print(\"Train data info: \\n\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest data info: \\n\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values with blank spaces\n",
    "test = test.fillna(' ')          \n",
    "train = train.fillna(' ')\n",
    "\n",
    "#Combine the columns title, author and text into one named total \n",
    "test['total'] = test['title'] + ' ' + test['author'] + test['text']          \n",
    "train['total'] = train['title'] + ' ' + train['author'] + train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
       "2        Why the Truth Might Get You Fired Consortiumne...\n",
       "3        15 Civilians Killed In Single US Airstrike Hav...\n",
       "4        Iranian woman jailed for fictional unpublished...\n",
       "6        Life: Life Of Luxury: Elton John’s 6 Favorite ...\n",
       "                               ...                        \n",
       "20788    Maine’s Gov. LePage Threatens To ‘Investigate’...\n",
       "20791    Lawyer Who Kept Hillary Campaign Chief Out of ...\n",
       "20793    Idiot Who Destroyed Trump Hollywood Star Gets ...\n",
       "20798    NATO, Russia To Hold Parallel Exercises In Bal...\n",
       "20799    What Keeps the F-35 Alive David Swanson  David...\n",
       "Name: total, Length: 10413, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns a pd series in which only real news is present\n",
    "#as label 1 corresponds to real news\n",
    "train[train['label']==1].total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading nltk data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#import stopwords from the nltk corpus\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# use stopwords of english language\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#we will iterate through each row of the train dataset\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    \n",
    "    #every row of 'total' column will be replaced by this filtered sentence\n",
    "    filter_sentence = ''\n",
    "    sentence = row['total']\n",
    "    \n",
    "    #remove all special characters, punctuations, symbols, digits using sub() method of python regex module\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) \n",
    "   \n",
    "    #tokenize the sentences\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    #list comprehension to remove stop words\n",
    "    words = [w for w in words if not w in stop_words]  #stopwords removal\n",
    "    \n",
    "    for word in words:\n",
    "    #lemmatize every word i.e convert every word to root form\n",
    "    #also convert every word to it's lowercase\n",
    "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
    "    \n",
    "    #change the data at the particular index by using loc attribute of pandas dataframe\n",
    "    train.loc[index,'total'] = filter_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with just CountVectorizer()(Bag of Words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  #Tfidf Vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer   #Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   #Bag of Words + Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['total','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['total']       #News in X_train\n",
    "Y_train = train['label']       #Label(Fake or Real) in Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into matrix form\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)\n",
    "freq_term_matrix = count_vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(freq_term_matrix, Y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model with BOW: 97.04%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2476,   88],\n",
       "       [  66, 2570]], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "print(\"Accuracy of logistic regression model with BOW: {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multionomial Naive Bayes model with BOW: 91.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2515,   49],\n",
       "       [ 373, 2263]], dtype=int64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "pred = NB.predict(X_test)\n",
    "print(\"Accuracy of Multionomial Naive Bayes model with BOW: {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine model with BOW: 93.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2429,  135],\n",
       "       [  55, 2581]], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmmod = svm.SVC()\n",
    "svmmod.fit(X_train, y_train)\n",
    "pred = svmmod.predict(X_test)\n",
    "print(\"Accuracy of Support Vector Machine model with BOW: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stochastic gradient descent model with BOW: 96.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2484,   80],\n",
       "       [ 102, 2534]], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sc = SGDClassifier()\n",
    "SGDmodel = sc.fit(X_train, y_train)\n",
    "prediction = SGDmodel.predict(X_test)\n",
    "print(\"Accuracy of Stochastic gradient descent model with BOW: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier model with BOW: 93.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2492,   72],\n",
       "       [ 246, 2390]], dtype=int64)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RandomForestmodel = RF.fit(X_train, y_train) \n",
    "prediction = RandomForestmodel.predict(X_test)\n",
    "print(\"Accuracy of Random Forest Classifier model with BOW: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using CountVectorizer and TfIdf-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['total','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['total']\n",
    "Y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using count vectorization and tfidf.\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)\n",
    "freq_term_matrix = count_vectorizer.transform(X_train)\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20800x220387 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5987666 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_matrix, Y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model with BOW and TF-IDF: 97.79%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2493,   71],\n",
       "       [  44, 2592]], dtype=int64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "print(\"Accuracy of logistic regression model with BOW and TF-IDF: {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multionomial Naive Bayes model with BOW and TF-IDF: 83.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2558,    6],\n",
       "       [ 853, 1783]], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "pred = NB.predict(X_test)\n",
    "print(\"Accuracy of Multionomial Naive Bayes model with BOW and TF-IDF: {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 97.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2480,   84],\n",
       "       [  55, 2581]], dtype=int64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmmod = svm.SVC()\n",
    "svmmod.fit(X_train, y_train)\n",
    "pred = svmmod.predict(X_test)\n",
    "print(\"accuracy : {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stochastic gradient descent model with BOW and TF-IDF: 97.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2485,   79],\n",
       "       [  48, 2588]], dtype=int64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sc = SGDClassifier()\n",
    "SGDmodel = sc.fit(X_train, y_train)\n",
    "prediction = SGDmodel.predict(X_test)\n",
    "print(\"Accuracy of Stochastic gradient descent model with BOW and TF-IDF: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier model with BOW and TF-IDF: 93.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2480,   84],\n",
       "       [  55, 2581]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RandomForestmodel = RF.fit(X_train, y_train) \n",
    "prediction = RandomForestmodel.predict(X_test)\n",
    "print(\"Accuracy of Random Forest Classifier model with BOW and TF-IDF: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with CountVectorizer, TfidfVectorizer and N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['total','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['total']\n",
    "Y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using count vectorization and tfidf.\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (3, 3))\n",
    "tfidf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_matrix = tfidf_vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_matrix, Y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20800x7914553 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9385902 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model with BOW and TF-IDF and N-Grams(Trigram): 89.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2065,  499],\n",
       "       [  27, 2609]], dtype=int64)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5, max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "print(\"Accuracy of logistic regression model with BOW and TF-IDF and N-Grams(Trigram): {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multionomial Naive Bayes model with BOW and TF-IDF and N-Grams(Trigram): 93.65%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2308,  256],\n",
       "       [  74, 2562]], dtype=int64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "pred = NB.predict(X_test)\n",
    "print(\"Accuracy of Multionomial Naive Bayes model with BOW and TF-IDF and N-Grams(Trigram): {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM model with BOW and TF-IDF and N-Grams(Trigram): 94.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2382,  182],\n",
       "       [  79, 2557]], dtype=int64)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmmod = svm.SVC()\n",
    "svmmod.fit(X_train, y_train)\n",
    "pred = svmmod.predict(X_test)\n",
    "print(\"Accuracy of SVM model with BOW and TF-IDF and N-Grams(Trigram): {}%\".format(round(accuracy_score(y_test, pred)*100,2)))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stochastic gradient descent model with BOW and TF-IDF and N-Grams(Trigram): 93.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2277,  287],\n",
       "       [  49, 2587]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sc = SGDClassifier()\n",
    "SGDmodel = sc.fit(X_train, y_train)\n",
    "prediction = SGDmodel.predict(X_test)\n",
    "print(\"Accuracy of Stochastic gradient descent model with BOW and TF-IDF and N-Grams(Trigram): {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model with best accuracy by using the concept of pipelining:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see that the logistic regression model with countVectorizer and TfidfTransformer gives the best accuracy(accuracy of 97.79%). So, we will save the model with concept of pipelining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging the variables again as once transformed vectors can't be transformed again using pipeline.\n",
    "X_train = train['total']\n",
    "Y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', linear_model.LogisticRegression(C=1e5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=100000.0))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"flynn hillary clinton big woman campus breitbart daniel j flynnever get feeling life circle roundabout rather head straight line toward intended destination hillary clinton remains big woman campus leafy liberal wellesley massachusetts everywhere else vote likely inauguration dress remainder day way miss havisham forever wore wedding dress speaking great expectations hillary rodham overflowed 48 year ago first addressed wellesley graduating class the president college informed gathered 1969 student needed debate far i could ascertain spokesman kind like democratic primary 2016 minus term unknown even seven sisters school i glad miss adams made clear i speaking today u 400 u miss rodham told classmate after appointing edger bergen charlie mccarthys mortimer snerds attendance bespectacled granny glass awarding matronly wisdom least john lennon wisdom took issue previous speaker despite becoming first win election seat u s senate since reconstruction edward brooke came criticism calling empathy goal protestors criticized tactic though clinton senior thesis saul alinsky lamented black power demagogue elitist arrogance repressive intolerance within new left similar word coming republican necessitated brief rebuttal trust rodham ironically observed 1969 one word i asked class rehearsal wanted say everyone came said talk trust talk lack trust u way feel others talk trust bust what say what say feeling permeates generation perhaps even understood distrusted the trust bust certainly busted clintons 2016 plan she certainly even understand people distrusted after whitewater travelgate vast conspiracy benghazi missing email clinton found distrusted voice friday there load compromising road broadening political horizon and distrust american people trump edged 48 percent 38 percent question immediately prior novembers election stood major reason closing horizon clinton described vanquisher supporter embracing lie con alternative fact assault truth reason she failed explain american people chose lie truth as history major among today know well people power invent fact attack question mark beginning end free society offered that hyperbole like many people emerge 1960s hillary clinton embarked upon long strange trip from high school goldwater girl wellesley college republican president democratic politician clinton drank time place gave degree more significantly went idealist cynic comparison two wellesley commencement address show way back lamented long leader viewed politics art possible challenge practice politics art making appears impossible possible now big woman campus odd woman white house wonder current station even possible why arent i 50 point ahead asked september in may asks isnt president the woman famously dubbed congenital liar bill safire concludes lie mind getting stood election day like finding jilted bride wedding day inspires dangerous delusion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fakenewspipeline.sav']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the pipeline\n",
    "filename = 'fakenewspipeline.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './fakenewspipeline.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict([\"flynn hillary clinton big woman campus breitbart daniel j flynnever get feeling life circle roundabout rather head straight line toward intended destination hillary clinton remains big woman campus leafy liberal wellesley massachusetts everywhere else vote likely inauguration dress remainder day way miss havisham forever wore wedding dress speaking great expectations hillary rodham overflowed 48 year ago first addressed wellesley graduating class the president college informed gathered 1969 student needed debate far i could ascertain spokesman kind like democratic primary 2016 minus term unknown even seven sisters school i glad miss adams made clear i speaking today u 400 u miss rodham told classmate after appointing edger bergen charlie mccarthys mortimer snerds attendance bespectacled granny glass awarding matronly wisdom least john lennon wisdom took issue previous speaker despite becoming first win election seat u s senate since reconstruction edward brooke came criticism calling empathy goal protestors criticized tactic though clinton senior thesis saul alinsky lamented black power demagogue elitist arrogance repressive intolerance within new left similar word coming republican necessitated brief rebuttal trust rodham ironically observed 1969 one word i asked class rehearsal wanted say everyone came said talk trust talk lack trust u way feel others talk trust bust what say what say feeling permeates generation perhaps even understood distrusted the trust bust certainly busted clintons 2016 plan she certainly even understand people distrusted after whitewater travelgate vast conspiracy benghazi missing email clinton found distrusted voice friday there load compromising road broadening political horizon and distrust american people trump edged 48 percent 38 percent question immediately prior novembers election stood major reason closing horizon clinton described vanquisher supporter embracing lie con alternative fact assault truth reason she failed explain american people chose lie truth as history major among today know well people power invent fact attack question mark beginning end free society offered that hyperbole like many people emerge 1960s hillary clinton embarked upon long strange trip from high school goldwater girl wellesley college republican president democratic politician clinton drank time place gave degree more significantly went idealist cynic comparison two wellesley commencement address show way back lamented long leader viewed politics art possible challenge practice politics art making appears impossible possible now big woman campus odd woman white house wonder current station even possible why arent i 50 point ahead asked september in may asks isnt president the woman famously dubbed congenital liar bill safire concludes lie mind getting stood election day like finding jilted bride wedding day inspires dangerous delusion\"])\n",
    "print(result) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
